
"""
æ³¨æ„ï¼šæœ¬ä»£ç ç›´æ¥æ˜¯.py æ–‡ä»¶çš„å†…å®¹, ä½ å¯ä»¥åˆ†æ®µå¤åˆ¶åˆ°jupyter(.ipynb)ä¸­è¿è¡Œï¼Œä½ ä¹Ÿå¯ä»¥ç›´æ¥æ‰§è¡Œæœ¬.py æ–‡ä»¶
æœ¬ä»£ç ç¤ºä¾‹å…·æœ‰è¶…çº§è¯¦ç»†çš„æ³¨é‡Š, å¦‚æœä¾ç„¶æœ‰ç–‘é—®, ä¼˜å…ˆé—®AI, è¦å…»æˆä¹ æƒ¯ï¼Œè¿™æ˜¯æ–°æ—¶ä»£äººç±»çš„ä¹ æƒ¯

å®ç°ä¸€ä¸ª Softmax å›å½’æ ‡ç­¾åˆ†ç±»æ¨¡å‹ï¼Œä½¿ç”¨ PyTorch æ¡†æ¶
æ•°æ®æ¥æº: MNIST-Fashion æ•°æ®é›†
æºä½œè€…: ä¾åŠ› EL@zju.edu.cn

åŸºäºLRçº¿æ€§å›å½’çš„ç¤ºä¾‹ä»£ç ä¹‹å¤–, éœ€è¦é¢å¤–å®‰è£…:
- torchvision: `pip install torchvision`
pytorchæ¡†æ¶ä¸­ä¸“é—¨ç”¨äºå¤„ç†å›¾åƒæ•°æ®çš„åº“, æä¾›äº†å¸¸ç”¨çš„æ•°æ®é›†å’Œé¢„å¤„ç†æ–¹æ³•
"""


import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt
import matplotlib
import emoji

# è‹±ä¼Ÿè¾¾ GPU é…ç½®
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(f"Using device: {device}")

# Apple Mç³»åˆ— GPU é…ç½®
# if torch.backends.mps.is_available():
#     device = torch.device("mps")  # ä½¿ç”¨ Apple GPU
# else:
#     print("âŒ MPS ä¸å¯ç”¨ï¼Œå›é€€åˆ° CPU")
# device = torch.device("mps"  else "cpu")

# Windowsç³»ç»Ÿé€‚ç”¨çš„ä¸­æ–‡å­—ä½“è®¾ç½®
matplotlib.rcParams['font.sans-serif'] = ['Arial Unicode MS', 'Microsoft YaHei', 'Segoe UI Emoji'] # Windowså¯ç”¨å­—ä½“
matplotlib.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜

# # è®¾ç½®æ”¯æŒä¸­æ–‡å­—ä½“ï¼ˆmacOSæ˜¯è¿™æ ·è®¾ç½®ï¼ŒWindowsé—®ä¸€ä¸‹AIï¼Œæˆ‘æ²¡æµ‹è¯•è¿‡ï¼‰
# matplotlib.rcParams['font.sans-serif'] = ['PingFang HK', 'Heiti TC', 'Arial Unicode MS']  # ä¼˜å…ˆä½¿ç”¨å¯ç”¨å­—ä½“
# matplotlib.rcParams['axes.unicode_minus'] = False  # è§£å†³è´Ÿå·æ˜¾ç¤ºä¸ºæ–¹å—çš„é—®é¢˜


# ========== 1. è®¾ç½®éšæœºç§å­ç¡®ä¿ç»“æœå¯å¤ç° ==========
# è®¾ç½® PyTorch ä¸­çš„éšæœºæ•°ç”Ÿæˆå™¨çš„ç§å­ä¸º 42ï¼Œä»¥ç¡®ä¿æ¯æ¬¡è¿è¡Œæ—¶ç”Ÿæˆçš„éšæœºæ•°æ˜¯ç›¸åŒçš„ï¼Œä»è€Œè®©ä½ çš„å®éªŒç»“æœå…·æœ‰â€œå¯å¤ç°æ€§â€
# åœ¨æ·±åº¦å­¦ä¹ ä¸­ï¼Œå¾ˆå¤šæ“ä½œéƒ½æ¶‰åŠéšæœºæ€§ï¼Œä¾‹å¦‚ï¼š
# åˆå§‹åŒ–æ¨¡å‹å‚æ•°ï¼ˆæƒé‡ï¼‰
# æ•°æ®åŠ è½½æ—¶çš„éšæœºæ‰“ä¹±ï¼ˆshuffleï¼‰
# æ•°æ®å¢å¼ºï¼ˆå¦‚éšæœºè£å‰ªã€æ—‹è½¬ç­‰ï¼‰
# è®¾ç½®éšæœºç§å­å¯ä»¥ç¡®ä¿æ¯æ¬¡è¿è¡Œæ—¶è¿™äº›éšæœºæ“ä½œçš„ç»“æœéƒ½æ˜¯ä¸€æ ·çš„
torch.manual_seed(42)


# ========== 2. æ•°æ®é¢„å¤„ç† ==========
transform = transforms.Compose([
    # å°†å›¾åƒè½¬æ¢ä¸ºå¼ é‡ï¼ŒèŒƒå›´å˜ä¸º [0, 1]ï¼Œå›¾åƒåŸå§‹åƒç´ å€¼ä¸€èˆ¬æ˜¯ 0~255ï¼Œç» ToTensor() è½¬æˆ Tensor åï¼Œä¼šå˜æˆ [0, 1] ä¹‹é—´çš„æµ®ç‚¹æ•°
    transforms.ToTensor(), 


    # æ ‡å‡†åŒ–åˆ° [-1, 1]ï¼Œæ ‡å‡†åŒ–çš„ä½œç”¨æ˜¯å°†è¿™äº›å€¼è¿›ä¸€æ­¥å˜æˆä¸€ä¸ªåˆ†å¸ƒæ›´é€‚åˆè®­ç»ƒçš„èŒƒå›´ï¼Œé€šå¸¸æ˜¯ å‡å€¼ä¸º0ï¼Œæ–¹å·®ä¸º1 çš„åˆ†å¸ƒï¼Œä¹Ÿå°±æ˜¯æ ‡å‡†æ­£æ€åˆ†å¸ƒï¼Œå°†åƒç´ å€¼ä»ä¸­å¿ƒå€¼ 0.5 å‡å»ï¼Œå˜æˆä»¥ 0 ä¸ºä¸­å¿ƒï¼ˆå¯¹ç§°ï¼‰ï¼Œå†é™¤ä»¥ 0.5ï¼Œæ‰©å¤§åˆ†å¸ƒèŒƒå›´ï¼ˆä» [0, 1] â†’ [-1, 1]ï¼‰
    # è‹¥åƒç´ å€¼ä¸º 1ï¼Œåˆ™å˜ä¸º (1 - 0.5) / 0.5 = 1ï¼›è‹¥åƒç´ å€¼ä¸º 0ï¼Œåˆ™å˜ä¸º (0 - 0.5) / 0.5 = -1ï¼›è‹¥åƒç´ å€¼ä¸º 0.5ï¼šåˆ™å˜ä¸º (0.5 - 0.5) / 0.5 = 0ï¼Œæ‰€ä»¥æ•´ä¸ªåƒç´ å€¼çš„èŒƒå›´ç”± [0, 1] è½¬æ¢æˆäº† [-1, 1]
    transforms.Normalize((0.5,), (0.5,))
])


# ========== 3. ä¸‹è½½å¹¶åŠ è½½æ•°æ®é›† ==========
train_dataset = datasets.FashionMNIST(root='data', train=True, download=True, transform=transform)
test_dataset = datasets.FashionMNIST(root='data', train=False, download=True, transform=transform)


# batch_sizeæ¯æ¬¡è¿­ä»£ç”¨å¤šå°‘ä¸ªæ ·æœ¬æ¥è®¡ç®—æ¢¯åº¦ï¼Œå°ï¼ˆå¦‚ 1 æˆ– 16ï¼‰å­¦ä¹ æ›´ç»†è‡´ã€æ³›åŒ–å¥½ï¼Œä½†è®­ç»ƒæ…¢ã€ä¸ç¨³å®šã€å™ªå£°å¤§ï¼›å¤§ï¼ˆå¦‚ 128 æˆ– 512ï¼‰ç¨³å®šã€é€Ÿåº¦å¿«ä½†æ³›åŒ–èƒ½åŠ›å·®ã€å†…å­˜å ç”¨å¤§ï¼›64ï¼ˆç»éªŒå€¼ï¼‰ç¨³å®šæ€§ + æ³›åŒ–æŠ˜ä¸­å¥½ï¼Œæ˜¯æ·±åº¦å­¦ä¹ ä¸­å¸¸ç”¨é»˜è®¤å€¼
# shuffle=Trueæ¯ä¸ª epoch éšæœºæ‰“ä¹±æ•°æ®é¡ºåºï¼Œé¿å…æ¨¡å‹å­¦åˆ°â€œæ ·æœ¬é¡ºåºçš„åè§â€ï¼Œå°¤å…¶å¯¹äºæ¢¯åº¦ä¸‹é™ï¼Œå¦‚æœæ¯æ¬¡ batch çš„é¡ºåºä¸€æ ·ï¼Œå¾ˆå®¹æ˜“é™·å…¥å±€éƒ¨æœ€ä¼˜æˆ–è¿‡æ‹Ÿåˆï¼Œshuffle=True æ¯ä¸€è½®éƒ½ä¼šé‡æ–°æ´—ç‰Œï¼Œä½¿å¾—æ¨¡å‹æ³›åŒ–èƒ½åŠ›æ›´å¼º
# å‡è®¾ä½ æ˜¯ä¸ªè€å¸ˆï¼Œè¦æ•™ 60 ä¸ªå­¦ç”Ÿè€ƒè¯•æŠ€å·§ï¼š
# å¦‚æœä½ æ¯æ¬¡ä¸Šè¯¾éƒ½è®©å‰ 10 ä¸ªæ˜¯å­¦éœ¸ï¼Œæœ€å 10 ä¸ªæ˜¯å­¦æ¸£ï¼Œå­¦ç”Ÿå°±å¯èƒ½å­¦ä¼šäº†â€œé¡ºåºâ€è€Œä¸æ˜¯â€œæŠ€å·§â€
# ä½ æŠŠå­¦ç”Ÿæ´—ç‰Œï¼Œéšæœº 10 äººä¸€ç»„ï¼Œæ¯èŠ‚è¯¾çš„å­¦ç”Ÿéƒ½ä¸ä¸€æ ·ï¼Œæ•™å­¦æ•ˆæœå°±æ›´å¹³å‡ï¼Œæ¨¡å‹æ³›åŒ–èƒ½åŠ›ä¹Ÿæ›´å¥½
train_loader = DataLoader(train_dataset, batch_size=64, shuffle=True) 
# test_loader æµ‹è¯•é›†é€šå¸¸ä¸éœ€è¦æ‰“ä¹±é¡ºåºï¼Œå› ä¸ºæˆ‘ä»¬åªå…³å¿ƒæœ€ç»ˆçš„å‡†ç¡®ç‡ï¼Œä¿æŒè¯„ä¼°ä¸€è‡´æ€§ï¼Œä¸éœ€è¦â€œæ³›åŒ–è®­ç»ƒâ€
test_loader = DataLoader(test_dataset, batch_size=64)


# ========== 4. ç±»åˆ«æ ‡ç­¾ ==========
class_names = [
    'T-shirt/top', 'Trouser', 'Pullover', 'Dress', 'Coat',
    'Sandal', 'Shirt', 'Sneaker', 'Bag', 'Ankle boot'
]

# ========== 5. å¯è§†åŒ–éƒ¨åˆ†å›¾åƒæ ·æœ¬ ==========
text = 'ğŸ¨ ç¤ºä¾‹è®­ç»ƒå›¾åƒ'
emoji_text = emoji.emojize(text, use_aliases = True )


def show_sample_images():
    images, labels = next(iter(train_loader))
    plt.figure(figsize=(10, 4))
    for i in range(6):
        plt.subplot(1, 6, i + 1)
        plt.imshow(images[i].squeeze(), cmap='gray')
        plt.title(class_names[labels[i]])
        plt.axis('off')
    plt.suptitle(emoji_text)
    plt.tight_layout()
    plt.show()


show_sample_images()


# ========== 6. æ„å»º Softmax å›å½’æ¨¡å‹ ==========
class SoftmaxRegression(nn.Module):
    def __init__(self):
        super().__init__()
        # è¾“å…¥å›¾åƒå¤§å°ä¸º 28x28ï¼Œå±•å¹³ä¸º 784 ç»´å‘é‡
        self.flatten = nn.Flatten()
        self.linear = nn.Linear(28 * 28, 10)  # 784 -> 10 ä¸ªç±»åˆ«

    def forward(self, x):
        x = self.flatten(x)
        logits = self.linear(x)  # è¾“å‡º raw scoreï¼ˆlogitsï¼‰
        return logits



model = SoftmaxRegression()


# ========== 7. æŸå¤±å‡½æ•° & ä¼˜åŒ–å™¨ ==========
# äº¤å‰ç†µæŸå¤±å‡½æ•°ï¼Œå†…éƒ¨æœ‰ä¸¤æ­¥ï¼šSoftmaxï¼šå°†æ¨¡å‹è¾“å‡ºçš„ logits è½¬ä¸ºæ¦‚ç‡åˆ†å¸ƒ; Log + NLLLossï¼šè®¡ç®—çœŸå®ç±»åˆ«å¯¹åº”ä½ç½®çš„å¯¹æ•°æ¦‚ç‡å¹¶å–è´Ÿ;æ‰€ä»¥ä½  ä¸éœ€è¦å†æ‰‹åŠ¨åŠ  softmaxï¼Œç›´æ¥ä¼  raw logits å°±è¡Œäº†
loss_fn = nn.CrossEntropyLoss()
# å®šä¹‰ä¼˜åŒ–å™¨ï¼ˆOptimizerï¼‰,éšæœºæ¢¯åº¦ä¸‹é™,å­¦ä¹ ç‡ä¸º 0.1ï¼Œè¡¨ç¤ºæ¯æ¬¡æ›´æ–°å‚æ•°æ—¶èµ°çš„â€œæ­¥é•¿â€ï¼Œå®é™…ä¸Šç”¨çš„æ˜¯ å°æ‰¹é‡éšæœºæ¢¯åº¦ä¸‹é™ï¼Œå› ä¸ºä½ ä¼ å…¥çš„æ˜¯å°æ‰¹é‡æ•°æ®
# 0.1 æ˜¯ä¸€ä¸ªç»éªŒå€¼ï¼Œå…¶å®å¹¶æ²¡æœ‰ä¸€ä¸ªæ”¾ä¹‹å››æµ·è€Œçš†å‡†çš„å€¼
optimizer = torch.optim.SGD(model.parameters(), lr=0.1)
# æƒ³ç”¨Adamï¼Ÿå¯ä»¥è¯•è¯•
# optimizer = torch.optim.Adam(model.parameters(), lr=0.001)


# ========== 8. è®­ç»ƒè¿‡ç¨‹ ==========
# å®šä¹‰è®­ç»ƒæ¨¡å‹çš„å‡½æ•°ï¼Œå‚æ•° num_epochs è¡¨ç¤ºè®­ç»ƒå¤šå°‘ä¸ªå‘¨æœŸï¼ˆæ•´ä¸ªè®­ç»ƒé›†è¢«æ¨¡å‹çœ‹å‡ éï¼‰
def train_model(num_epochs=5):
    # éå†æ¯ä¸€ä¸ª epochï¼ˆè®­ç»ƒå‘¨æœŸï¼‰
    for epoch in range(num_epochs):
        running_loss = 0.0  # ç´¯è®¡æ¯è½®çš„æ€»æŸå¤±
        correct = 0         # ç´¯è®¡é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
        total = 0           # ç´¯è®¡æ€»æ ·æœ¬æ•°ï¼Œç”¨äºè®¡ç®—å‡†ç¡®ç‡

        # éå†è®­ç»ƒé›†çš„æ¯ä¸€ä¸ª batchï¼ˆå°æ‰¹é‡ï¼‰ï¼Œæ¯ä¸ª batch åŒ…å«ä¸€ç»„å›¾åƒå’Œå¯¹åº”æ ‡ç­¾
        for images, labels in train_loader:
            # å°†ä¸€æ‰¹å›¾åƒè¾“å…¥æ¨¡å‹ï¼Œå¾—åˆ°é¢„æµ‹çš„åŸå§‹åˆ†æ•°ï¼ˆlogitsï¼‰
            outputs = model(images)

            # è®¡ç®—å½“å‰ batch çš„æŸå¤±ï¼ˆé¢„æµ‹å€¼ outputs ä¸çœŸå®æ ‡ç­¾ labels çš„å·®è·ï¼‰
            loss = loss_fn(outputs, labels)

            # æ¸…é™¤ä¹‹å‰ batch çš„æ¢¯åº¦ï¼Œé¿å…æ¢¯åº¦ç´¯åŠ 
            optimizer.zero_grad()

            # åå‘ä¼ æ’­ï¼šè‡ªåŠ¨è®¡ç®—æ‰€æœ‰æ¨¡å‹å‚æ•°å¯¹æŸå¤±å‡½æ•°çš„æ¢¯åº¦
            loss.backward()

            # æ›´æ–°æ¨¡å‹å‚æ•°ï¼ˆæ ¹æ®åˆšåˆšè®¡ç®—å‡ºçš„æ¢¯åº¦è°ƒæ•´å‚æ•°ï¼‰
            optimizer.step()

            # ç´¯åŠ æŸå¤±å€¼ï¼Œ.item() æ˜¯å°†å¼ é‡è½¬ä¸º Python æ•°å€¼
            running_loss += loss.item()

            # torch.max(outputs, 1) è¿”å›æœ€å¤§å€¼å’Œå¯¹åº”ä¸‹æ ‡ï¼Œè¿™é‡Œæˆ‘ä»¬å–ä¸‹æ ‡ï¼ˆå³é¢„æµ‹çš„ç±»åˆ«ï¼‰
            _, predicted = torch.max(outputs.data, 1)

            # ç»Ÿè®¡è¿™ä¸€æ‰¹çš„æ€»æ ·æœ¬æ•°
            total += labels.size(0)

            # ç»Ÿè®¡è¿™ä¸€æ‰¹ä¸­é¢„æµ‹æ­£ç¡®çš„æ•°é‡ï¼ˆä¸çœŸå®æ ‡ç­¾æ¯”å¯¹ï¼‰
            correct += (predicted == labels).sum().item()

        # æ¯ä¸ª epoch ç»“æŸåï¼Œè®¡ç®—è®­ç»ƒå‡†ç¡®ç‡
        acc = 100 * correct / total

        # æ‰“å°å½“å‰ epoch çš„å¹³å‡æŸå¤±å’Œå‡†ç¡®ç‡
        print(f"Epoch {epoch + 1}, Loss: {running_loss:.4f}, Accuracy: {acc:.2f}%")

train_model()


# ========== 9. æµ‹è¯•é›†ä¸Šè¯„ä¼°æ¨¡å‹ ==========
def test_model():
    # å…³é—­ Dropoutï¼ˆéšæœºä¸¢å¼ƒéƒ¨åˆ†ç¥ç»å…ƒï¼Œé˜²æ­¢è¿‡æ‹Ÿåˆï¼‰ã€BatchNormï¼ˆä½¿ç”¨å½“å‰ batch çš„å‡å€¼å’Œæ–¹å·®è¿›è¡Œå½’ä¸€åŒ–ï¼‰ ç­‰è®­ç»ƒæ—¶ç‰¹æœ‰çš„è¡Œä¸ºï¼Œç¡®ä¿æ¨ç†æ—¶æ¨¡å‹è¡¨ç°ä¸€è‡´ã€ç¨³å®šï¼Œæ¨¡å‹è¿›å…¥è¯„ä¼°æ¨¡å¼
    model.eval()
    correct = 0
    total = 0
    # åœ¨æ¨ç†æˆ–æµ‹è¯•æ—¶ç¦ç”¨æ¢¯åº¦è®¡ç®—ï¼ŒèŠ‚çœå†…å­˜å’Œè®¡ç®—èµ„æºï¼Œå¹¶åŠ å¿«é€Ÿåº¦ï¼ˆå› ä¸ºä¸éœ€è¦åå‘ä¼ æ’­ï¼‰
    with torch.no_grad():
        correct = 0      # ç”¨äºç´¯è®¡é¢„æµ‹æ­£ç¡®çš„æ ·æœ¬æ•°
        total = 0        # ç”¨äºç´¯è®¡æµ‹è¯•é›†çš„æ€»æ ·æœ¬æ•°

        # éå†æ•´ä¸ªæµ‹è¯•é›†çš„æ•°æ®åŠ è½½å™¨ï¼ˆæŒ‰ batch åŠ è½½ï¼‰
        for images, labels in test_loader:
            # å°†å›¾åƒé€å…¥æ¨¡å‹è¿›è¡Œå‰å‘ä¼ æ’­ï¼Œè¾“å‡ºä¸ºæ¯ç±»çš„æ‰“åˆ†ï¼ˆlogitsï¼‰
            outputs = model(images)

            # ä» logits ä¸­å–æ¯ä¸ªæ ·æœ¬å¾—åˆ†æœ€å¤§çš„ç´¢å¼•ï¼Œä½œä¸ºé¢„æµ‹çš„ç±»åˆ«
            _, predicted = torch.max(outputs.data, 1)

            # ç´¯åŠ å½“å‰ batch çš„æ ·æœ¬æ•°é‡
            total += labels.size(0)

            # å°†é¢„æµ‹ä¸çœŸå®æ ‡ç­¾é€ä¸ªå¯¹æ¯”ï¼Œç»Ÿè®¡é¢„æµ‹æ­£ç¡®çš„ä¸ªæ•°
            correct += (predicted == labels).sum().item()

        # è®¡ç®—æ•´ä½“æµ‹è¯•å‡†ç¡®ç‡
        accuracy = 100 * correct / total
        print(f"âœ… æµ‹è¯•å‡†ç¡®ç‡ï¼š{accuracy:.2f}%")

test_model()

# ========== 10. å¯è§†åŒ–é¢„æµ‹ç»“æœ ==========
def visualize_predictions():
    model.eval()
    # next() ä¼šä» test_loader ä¸­å–å‡ºç¬¬ä¸€ä¸ª batchï¼Œä¹Ÿå°±æ˜¯æµ‹è¯•é›†çš„å‰ 64 å¼ å›¾åƒå’Œå¯¹åº”æ ‡ç­¾ï¼Œimages: ä¸€ä¸ªåŒ…å«å¤šä¸ªå›¾åƒçš„å¼ é‡ï¼Œå½¢çŠ¶æ˜¯ [batch_size, 1, 28, 28]ï¼Œlabels: ä¸€ä¸ªåŒ…å«å¤šä¸ªå›¾åƒå¯¹åº”æ ‡ç­¾çš„å¼ é‡ï¼Œå½¢çŠ¶æ˜¯ [batch_size]
    images, labels = next(iter(test_loader))
    outputs = model(images)
    _, predicted = torch.max(outputs.data, 1)

    plt.figure(figsize=(12, 4))
    for i in range(6):
        plt.subplot(1, 6, i + 1)
        plt.imshow(images[i].squeeze(), cmap='gray')
        plt.title(f"Pred: {class_names[predicted[i]]}")
        plt.axis('off')
    plt.suptitle("ğŸ” æ¨¡å‹åœ¨æµ‹è¯•é›†ä¸Šçš„é¢„æµ‹")
    plt.tight_layout()
    plt.show()

visualize_predictions()

torch.save(model.state_dict(), "softmax_mnist_fashion.pt")